{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NNLM_Torch.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"mvlw9p3tPJjr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1594972407375,"user_tz":-540,"elapsed":803,"user":{"displayName":"Seungsoo Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1uuRhx1gX7RpM4meINkxmOV3SaJzuKi1t8THz=s64","userId":"15738127024040559934"}},"outputId":"6c9e78c0-604a-43b6-d60b-179a07314a8f"},"source":["# code by Tae Hwan Jung @graykode\n","\n","# 2020.07.17. code review by Seungsoo Lee @teddy309\n","# add comments.\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","dtype = torch.FloatTensor\n","\n","sentences =[\"hi my name is seung soo\", \"oh really ?\", \"thank you\"] #[ \"i like dog\", \"i love coffee\", \"i hate milk\"]\n","\n","word_list = \" \".join(sentences).split() #word_list에 각 단어 대입. \n","word_list = list(set(word_list)) #중복제거\n","word_dict = {w: i for i, w in enumerate(word_list)} #word로 인덱스를 찾는 dictionary\n","number_dict = {i: w for i, w in enumerate(word_list)}\n","n_class = len(word_dict) # number of Vocabulary\n","\n","#test\n","print(word_list)\n","print(word_dict)\n","print(number_dict)\n","print(sentences[1])\n","print(sentences[1].split()[:0])\n","print(word_list[1:5:2])"],"execution_count":27,"outputs":[{"output_type":"stream","text":["['my', 'is', 'soo', 'name', 'you', 'really', 'thank', 'hi', 'seung', 'oh', '?']\n","{'my': 0, 'is': 1, 'soo': 2, 'name': 3, 'you': 4, 'really': 5, 'thank': 6, 'hi': 7, 'seung': 8, 'oh': 9, '?': 10}\n","{0: 'my', 1: 'is', 2: 'soo', 3: 'name', 4: 'you', 5: 'really', 6: 'thank', 7: 'hi', 8: 'seung', 9: 'oh', 10: '?'}\n","oh really ?\n","[]\n","['is', 'name']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SUcUY1IEM_pv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1594972407664,"user_tz":-540,"elapsed":1084,"user":{"displayName":"Seungsoo Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1uuRhx1gX7RpM4meINkxmOV3SaJzuKi1t8THz=s64","userId":"15738127024040559934"}},"outputId":"43268f01-b2aa-4931-82d0-f37b9264b5a0"},"source":["# NNLM Parameter\n","n_step = 2 # n-1(n= layer 수) in paper (http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n","n_hidden = 2 # h in paper\n","m = 2 # m(차원 수) in paper\n","\n","def make_batch(sentences):\n","    input_batch = []\n","    target_batch = []\n","\n","    for sen in sentences:\n","        word = sen.split()\n","        input = [word_dict[n] for n in word[:-1]]\n","        target = word_dict[word[-1]]\n","\n","        input_batch.append(input)\n","        target_batch.append(target)\n","\n","    return input_batch, target_batch\n","\n","# Model\n","class NNLM(nn.Module):\n","    def __init__(self):\n","        super(NNLM, self).__init__()\n","        self.C = nn.Embedding(n_class, m) #matrix C[h*(n-1)m]: \n","        self.H = nn.Parameter(torch.randn(n_step * m, n_hidden).type(dtype)) #matrix H[h*(n-1)]: 가중치(입력층->은닉층)\n","        self.W = nn.Parameter(torch.randn(n_step * m, n_class).type(dtype)) #\n","        self.d = nn.Parameter(torch.randn(n_hidden).type(dtype)) #vetcor d[h*1]: \n","        self.U = nn.Parameter(torch.randn(n_hidden, n_class).type(dtype)) #matrix U[V*h]: \n","        self.b = nn.Parameter(torch.randn(n_class).type(dtype)) #vector b[V*1]:\n","\n","    def forward(self, X):\n","        X = self.C(X)\n","        X = X.view(-1, n_step * m) # [batch_size, n_step * n_class] #\n","        tanh = torch.tanh(self.d + torch.mm(X, self.H)) # [batch_size, n_hidden] #tanh(score:Ywt)\n","        output = self.b + torch.mm(X, self.W) + torch.mm(tanh, self.U) # [batch_size, n_class]\n","        return output\n","\n","#test\n","input_batch, target_batch = make_batch(sentences)\n","print(input_batch)\n","print(target_batch)\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[[7, 0, 3, 1, 8], [9, 5], [6]]\n","[2, 10, 4]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FWJ9DMjdMupE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"status":"error","timestamp":1594972407664,"user_tz":-540,"elapsed":1076,"user":{"displayName":"Seungsoo Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj1uuRhx1gX7RpM4meINkxmOV3SaJzuKi1t8THz=s64","userId":"15738127024040559934"}},"outputId":"5e3c3d0b-d6eb-493d-da5c-f2e78d571c86"},"source":["model = NNLM()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","input_batch, target_batch = make_batch(sentences)\n","input_batch = Variable(torch.LongTensor(input_batch))\n","target_batch = Variable(torch.LongTensor(target_batch))\n","\n","# Training\n","for epoch in range(5000):\n","\n","    optimizer.zero_grad()\n","    output = model(input_batch)\n","\n","    # output : [batch_size, n_class], target_batch : [batch_size] (LongTensor, not one-hot)\n","    loss = criterion(output, target_batch)\n","    if (epoch + 1)%1000 == 0:\n","        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","# Predict\n","predict = model(input_batch).data.max(1, keepdim=True)[1]\n","\n","# Test\n","print([sen.split()[:2] for sen in sentences], '->', [number_dict[n.item()] for n in predict.squeeze()])"],"execution_count":29,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-be0066f2b4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 5 at dim 1 (got 2)"]}]}]}